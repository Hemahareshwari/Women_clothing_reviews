{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "## Context\n",
    "\n",
    "This is a Women’s Clothing E-Commerce dataset revolving around the reviews written by customers. Its nine supportive features offer a great environment to parse out the text through its multiple dimensions. Because this is real commercial data, it has been anonymized, and references to the company in the review text and body have been replaced with “retailer”.\n",
    "\n",
    "## Content\n",
    "\n",
    "This dataset includes 23486 rows and 10 feature variables. Each row corresponds to a customer review, and includes the variables:\n",
    "\n",
    "Clothing ID: Integer Categorical variable that refers to the specific piece being reviewed.\n",
    "\n",
    "Age: Positive Integer variable of the reviewers age.\n",
    "\n",
    "Title: String variable for the title of the review.\n",
    "\n",
    "Review Text: String variable for the review body.\n",
    "\n",
    "Rating: Positive Ordinal Integer variable for the product score granted by the customer from 1 Worst, to 5 Best.\n",
    "\n",
    "Recommended IND: Binary variable stating where the customer recommends the product where 1 is recommended, 0 is not recommended.\n",
    "\n",
    "Positive Feedback Count: Positive Integer documenting the number of other customers who found this review positive.\n",
    "\n",
    "Division Name: Categorical name of the product high level division.\n",
    "\n",
    "Department Name: Categorical name of the product department name.\n",
    "\n",
    "Class Name: Categorical name of the product class name.\n",
    "\n",
    "## Problem approach\n",
    "\n",
    "This problem can be considered as a Classification or Regression problem.Our approach is to solve it as an Multiple Classification problem.\n",
    "\n",
    "We have considered 'Rating' as the Target variable. The main objective is to predict the Women's clothing rating based on the customer reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/insofe/anaconda3/envs/py35tf1/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/insofe/anaconda3/envs/py35tf1/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/insofe/anaconda3/envs/py35tf1/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/insofe/anaconda3/envs/py35tf1/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/insofe/anaconda3/envs/py35tf1/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/insofe/anaconda3/envs/py35tf1/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler,LabelEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.layers import Input,Embedding,Dense,Flatten,concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from IPython.display import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('Womens Clothing E-Commerce Reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23486, 11)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age                    Title  \\\n",
       "0           0          767   33                      NaN   \n",
       "1           1         1080   34                      NaN   \n",
       "2           2         1077   60  Some major design flaws   \n",
       "3           3         1049   50         My favorite buy!   \n",
       "4           4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23481</th>\n",
       "      <td>23481</td>\n",
       "      <td>1104</td>\n",
       "      <td>34</td>\n",
       "      <td>Great dress for many occasions</td>\n",
       "      <td>I was very happy to snag this dress at such a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23482</th>\n",
       "      <td>23482</td>\n",
       "      <td>862</td>\n",
       "      <td>48</td>\n",
       "      <td>Wish it was made of cotton</td>\n",
       "      <td>It reminds me of maternity clothes. soft, stre...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23483</th>\n",
       "      <td>23483</td>\n",
       "      <td>1104</td>\n",
       "      <td>31</td>\n",
       "      <td>Cute, but see through</td>\n",
       "      <td>This fit well, but the top was very see throug...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23484</th>\n",
       "      <td>23484</td>\n",
       "      <td>1084</td>\n",
       "      <td>28</td>\n",
       "      <td>Very cute dress, perfect for summer parties an...</td>\n",
       "      <td>I bought this dress for a wedding i have this ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23485</th>\n",
       "      <td>23485</td>\n",
       "      <td>1104</td>\n",
       "      <td>52</td>\n",
       "      <td>Please make more like this one!</td>\n",
       "      <td>This dress in a lovely platinum is feminine an...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Clothing ID  Age  \\\n",
       "23481       23481         1104   34   \n",
       "23482       23482          862   48   \n",
       "23483       23483         1104   31   \n",
       "23484       23484         1084   28   \n",
       "23485       23485         1104   52   \n",
       "\n",
       "                                                   Title  \\\n",
       "23481                     Great dress for many occasions   \n",
       "23482                         Wish it was made of cotton   \n",
       "23483                              Cute, but see through   \n",
       "23484  Very cute dress, perfect for summer parties an...   \n",
       "23485                    Please make more like this one!   \n",
       "\n",
       "                                             Review Text  Rating  \\\n",
       "23481  I was very happy to snag this dress at such a ...       5   \n",
       "23482  It reminds me of maternity clothes. soft, stre...       3   \n",
       "23483  This fit well, but the top was very see throug...       3   \n",
       "23484  I bought this dress for a wedding i have this ...       3   \n",
       "23485  This dress in a lovely platinum is feminine an...       5   \n",
       "\n",
       "       Recommended IND  Positive Feedback Count   Division Name  \\\n",
       "23481                1                        0  General Petite   \n",
       "23482                1                        0  General Petite   \n",
       "23483                0                        1  General Petite   \n",
       "23484                1                        2         General   \n",
       "23485                1                       22  General Petite   \n",
       "\n",
       "      Department Name Class Name  \n",
       "23481         Dresses    Dresses  \n",
       "23482            Tops      Knits  \n",
       "23483         Dresses    Dresses  \n",
       "23484         Dresses    Dresses  \n",
       "23485         Dresses    Dresses  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19662.0</td>\n",
       "      <td>19662.000000</td>\n",
       "      <td>19662</td>\n",
       "      <td>19662</td>\n",
       "      <td>19662.0</td>\n",
       "      <td>19662.0</td>\n",
       "      <td>19662.000000</td>\n",
       "      <td>19662</td>\n",
       "      <td>19662</td>\n",
       "      <td>19662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1095.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13983</td>\n",
       "      <td>19656</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1078.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love it!</td>\n",
       "      <td>Perfect fit and i've gotten so many compliment...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>871.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>10858.0</td>\n",
       "      <td>16087.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11664</td>\n",
       "      <td>8713</td>\n",
       "      <td>5371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>43.260808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.652477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12.258122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.834285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Clothing ID           Age     Title  \\\n",
       "count       19662.0  19662.000000     19662   \n",
       "unique       1095.0           NaN     13983   \n",
       "top          1078.0           NaN  Love it!   \n",
       "freq          871.0           NaN       136   \n",
       "mean            NaN     43.260808       NaN   \n",
       "std             NaN     12.258122       NaN   \n",
       "min             NaN     18.000000       NaN   \n",
       "25%             NaN     34.000000       NaN   \n",
       "50%             NaN     41.000000       NaN   \n",
       "75%             NaN     52.000000       NaN   \n",
       "max             NaN     99.000000       NaN   \n",
       "\n",
       "                                              Review Text   Rating  \\\n",
       "count                                               19662  19662.0   \n",
       "unique                                              19656      5.0   \n",
       "top     Perfect fit and i've gotten so many compliment...      5.0   \n",
       "freq                                                    3  10858.0   \n",
       "mean                                                  NaN      NaN   \n",
       "std                                                   NaN      NaN   \n",
       "min                                                   NaN      NaN   \n",
       "25%                                                   NaN      NaN   \n",
       "50%                                                   NaN      NaN   \n",
       "75%                                                   NaN      NaN   \n",
       "max                                                   NaN      NaN   \n",
       "\n",
       "        Recommended IND  Positive Feedback Count Division Name  \\\n",
       "count           19662.0             19662.000000         19662   \n",
       "unique              2.0                      NaN             3   \n",
       "top                 1.0                      NaN       General   \n",
       "freq            16087.0                      NaN         11664   \n",
       "mean                NaN                 2.652477           NaN   \n",
       "std                 NaN                 5.834285           NaN   \n",
       "min                 NaN                 0.000000           NaN   \n",
       "25%                 NaN                 0.000000           NaN   \n",
       "50%                 NaN                 1.000000           NaN   \n",
       "75%                 NaN                 3.000000           NaN   \n",
       "max                 NaN               122.000000           NaN   \n",
       "\n",
       "       Department Name Class Name  \n",
       "count            19662      19662  \n",
       "unique               6         20  \n",
       "top               Tops    Dresses  \n",
       "freq              8713       5371  \n",
       "mean               NaN        NaN  \n",
       "std                NaN        NaN  \n",
       "min                NaN        NaN  \n",
       "25%                NaN        NaN  \n",
       "50%                NaN        NaN  \n",
       "75%                NaN        NaN  \n",
       "max                NaN        NaN  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                  int64\n",
       "Clothing ID                 int64\n",
       "Age                         int64\n",
       "Title                      object\n",
       "Review Text                object\n",
       "Rating                      int64\n",
       "Recommended IND             int64\n",
       "Positive Feedback Count     int64\n",
       "Division Name              object\n",
       "Department Name            object\n",
       "Class Name                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the column Unnamed:0 since it has sequence of unique numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(labels=['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clothing ID  Age                    Title  \\\n",
       "0          767   33                      NaN   \n",
       "1         1080   34                      NaN   \n",
       "2         1077   60  Some major design flaws   \n",
       "3         1049   50         My favorite buy!   \n",
       "4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify the unique values for each of the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clothing ID\n",
      "1206\n",
      "Age\n",
      "77\n",
      "Title\n",
      "13994\n",
      "Review Text\n",
      "22635\n",
      "Rating\n",
      "5\n",
      "Recommended IND\n",
      "2\n",
      "Positive Feedback Count\n",
      "82\n",
      "Division Name\n",
      "4\n",
      "Department Name\n",
      "7\n",
      "Class Name\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "for i in data.columns.values:\n",
    "    print (i)\n",
    "    #print (pd.value_counts(data[i].values,))\n",
    "    print (len(data[i].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clothing ID\n",
      "1078    1024\n",
      "862      806\n",
      "1094     756\n",
      "1081     582\n",
      "872      545\n",
      "829      527\n",
      "1110     480\n",
      "868      430\n",
      "895      404\n",
      "936      358\n",
      "867      351\n",
      "850      338\n",
      "1095     327\n",
      "863      306\n",
      "1077     297\n",
      "1059     294\n",
      "1086     291\n",
      "1080     289\n",
      "860      288\n",
      "1083     249\n",
      "861      244\n",
      "873      238\n",
      "828      225\n",
      "1092     220\n",
      "1033     220\n",
      "927      214\n",
      "1056     213\n",
      "820      211\n",
      "836      205\n",
      "1022     205\n",
      "        ... \n",
      "88         1\n",
      "72         1\n",
      "56         1\n",
      "1191       1\n",
      "1175       1\n",
      "1183       1\n",
      "1127       1\n",
      "887        1\n",
      "600        1\n",
      "648        1\n",
      "680        1\n",
      "712        1\n",
      "137        1\n",
      "105        1\n",
      "89         1\n",
      "73         1\n",
      "57         1\n",
      "41         1\n",
      "25         1\n",
      "9          1\n",
      "1176       1\n",
      "1160       1\n",
      "1032       1\n",
      "856        1\n",
      "808        1\n",
      "792        1\n",
      "776        1\n",
      "744        1\n",
      "728        1\n",
      "0          1\n",
      "Length: 1206, dtype: int64\n",
      "Age\n",
      "39    1269\n",
      "35     909\n",
      "36     842\n",
      "34     804\n",
      "38     780\n",
      "37     766\n",
      "41     741\n",
      "33     725\n",
      "46     713\n",
      "42     651\n",
      "32     631\n",
      "48     626\n",
      "44     617\n",
      "40     617\n",
      "43     579\n",
      "31     569\n",
      "47     564\n",
      "53     560\n",
      "45     529\n",
      "29     513\n",
      "49     490\n",
      "56     471\n",
      "52     442\n",
      "28     428\n",
      "26     423\n",
      "30     407\n",
      "50     398\n",
      "54     395\n",
      "51     393\n",
      "57     363\n",
      "      ... \n",
      "69     113\n",
      "20     108\n",
      "21     102\n",
      "70      93\n",
      "71      51\n",
      "74      50\n",
      "72      46\n",
      "83      43\n",
      "73      40\n",
      "19      40\n",
      "75      26\n",
      "77      18\n",
      "79      15\n",
      "78      15\n",
      "82      13\n",
      "76      10\n",
      "80      10\n",
      "85       6\n",
      "84       6\n",
      "89       5\n",
      "91       5\n",
      "81       5\n",
      "18       4\n",
      "87       4\n",
      "94       3\n",
      "93       2\n",
      "90       2\n",
      "86       2\n",
      "99       2\n",
      "92       1\n",
      "Length: 77, dtype: int64\n",
      "Title\n",
      "Love it!                                         136\n",
      "Beautiful                                         95\n",
      "Love                                              88\n",
      "Love!                                             84\n",
      "Beautiful!                                        72\n",
      "Beautiful dress                                   60\n",
      "Love it                                           59\n",
      "Love this dress!                                  53\n",
      "Gorgeous                                          53\n",
      "Cute top                                          52\n",
      "Disappointed                                      51\n",
      "Perfect                                           49\n",
      "Great dress                                       49\n",
      "Super cute                                        44\n",
      "Adorable                                          43\n",
      "Great top                                         42\n",
      "Not for me                                        37\n",
      "Runs small                                        36\n",
      "Great top!                                        35\n",
      "Disappointing                                     35\n",
      "Perfect!                                          35\n",
      "Great dress!                                      35\n",
      "Love this dress                                   34\n",
      "Beautiful top                                     34\n",
      "Cute                                              34\n",
      "Lovely                                            33\n",
      "Great fit                                         31\n",
      "Cute!                                             31\n",
      "Love this!                                        29\n",
      "Gorgeous!                                         28\n",
      "                                                ... \n",
      "Exceptional design                                 1\n",
      "Such a fun top!                                    1\n",
      "Soooo disappointed!                                1\n",
      "Love the turquoise graphic design                  1\n",
      "Great details and fit!                             1\n",
      "Pretty frock..                                     1\n",
      "Comfy, elegant, slimming                           1\n",
      "Amazing casul top                                  1\n",
      "Soft, snuggly and cute                             1\n",
      "These pants are like wearing angel wings!          1\n",
      "Charcoal, pale gray, a bit of silver!              1\n",
      "Love/hate relationship with this dress             1\n",
      "Simple classic                                     1\n",
      "Great dress, poor stitching                        1\n",
      "Great classic boyfriend jean (not distressed)      1\n",
      "Gorgeous blouse, stunning color and pattern        1\n",
      "Weird bunching in the front                        1\n",
      "Flattering and comfy - my perfect jean!            1\n",
      "Adorable! very flattering!                         1\n",
      "Day to night                                       1\n",
      "Sizing up wasn't necessary for me...               1\n",
      "Made poorly, but still kinda cute                  1\n",
      "Summer simple                                      1\n",
      "Oops forgot to dry clean                           1\n",
      "Wanted to love but couldn't.                       1\n",
      "Not so much                                        1\n",
      "Material not as expected                           1\n",
      "Wanted to love it but way too short!!!             1\n",
      "Nice top but runs large                            1\n",
      "What's with the pockets?                           1\n",
      "Length: 13993, dtype: int64\n",
      "Review Text\n",
      "Perfect fit and i've gotten so many compliments. i buy all my suits from here now!                                                                                                                                                                                                                                                                                                                                                                                                                                        3\n",
      "The sweater and skirt are so pretty! they're really soft and have such an easy, comfortable look together. really love this gorgeous outfit.\\n\\ni am borderline small/medium and kept the size small after trying both on.                                                                                                                                                                                                                                                                                                2\n",
      "Lightweight, soft cotton top and shorts. i think it's meant to be a beach cover-up but i'm wearing it as a thin, light-weight summer outfit on these hot hot days. the top has a loose elastic around the bottom which i didn't realize when i ordered it, but i like it and it matches the look in the photos. and the shorts are very low-cut - don't expect them up around your waist. again, i like that. some might want to wear a cami underneath because it's a thin cotton but i'm fine as-is. i bought it i      2\n",
      "Love, love these jeans. being short they come right to my ankle. super soft and don?t require any hemming. i ordered my typical jean size of 26 and they fit like a glove. would love to have these in black and grey.                                                                                                                                                                                                                                                                                                    2\n",
      "I bought this shirt at the store and after going home and trying it on, i promptly went online and ordered two more! i've gotten multiple compliments anytime i wear any of them. great for looking put together with no fuss. \\r\\npeople that have commented there's were destroyed in the wash didn't read the care label which says dry clean.                                                                                                                                                                         2\n",
      "I purchased this and another eva franco dress during retailer's recent 20% off sale. i was looking for dresses that were work appropriate, but that would also transition well to happy hour or date night. they both seemed to be just what i was looking for. i ordered a 4 regular and a 6 regular, as i am usually in between sizes. the 4 was definitely too small. the 6 fit, technically, but was very ill fitting. not only is the dress itself short, but it is very short-waisted. i am only 5'3\", but it fe    2\n",
      "I tried this top on in the store and didn't buy it because i was in a hurry. obsessed about it and it was sold out when i went back. so happy i was able to get it online, it's beautiful. i got a medium and it fits perfectly, enough room that it hangs nicely but not baggy, i'm typically a medium in shirts at retailer. it looks beautiful with high waisted black pants. i wear a cami underneath. i own it in white and tried it on with a black bra only and it looked great, i just didn't feel comfortable    1\n",
      "5,7\" , 138 pound,, 73 year old grandmother. can't wear wool and always looking for stylish cotton/linen sweaters.\\r\\nordered m based on reviews. very tight across back and sleeves too short. loved the style, the below hip length, and color so reordered in a large. still waiting for sweater. hoping it fits better                                                                                                                                                                                                 1\n",
      "Comfortable and flows well, does run large, order one size smaller.                                                                                                                                                                                                                                                                                                                                                                                                                                                       1\n",
      "I really loved the pattern and style of this dress! unfortunately, i had to return it because i have broad shoulders and it is a pretty stiff top that cut into the flabby area near my armpits. for most people it's probably perfect! but if you have wide shoulders or any concerns about the armpit flab, this might not be a great choice for you.                                                                                                                                                                   1\n",
      "I'm 5'8\" and a 2/xs and this fit well in size 2, waist was actually a bit loose. unfortunately the waist hit at least 2\" too high -- on my ribcage. not cute or flattering. that was the only flaw. would be perfect on someone about 5'6\". otherwise the dress looked exactly as pictured. love the boho vibe of this dress, the lace, sleeve length, and cotton material. could easily be dressed up or down. the style feels a little edgy - not too sweet. i am so sad to return this.                                1\n",
      "The dress is true to size, but has generous stretch to it. i absolutely love this dress, i compliments where needed and hides what needs to be hid, for me the tummy!                                                                                                                                                                                                                                                                                                                                                     1\n",
      "I love this top and despite the higher price point, it came home with me. normally i tend to go for very basic colors - white, black, gray. but i saw this and was intrigued by the high neck and subtle cut away sleeveless style. tried it on and it was love. the fit is great. it is flowey, but without the maternity look in front and all that extra fabric in the back. it's just right. i love the print and i am so not a print person. i tried it on with some taupe skinny jeans and a denim jacket. per      1\n",
      "It's way more distressed than it looks in the picture and that was a no for me.                                                                                                                                                                                                                                                                                                                                                                                                                                           1\n",
      "These look nothing like the picture! they are super high-waisted & longer than they look in this picture. i felt as if i was wearing a pair of jeans from the 90's that just fit terribly. i thought they were going to be a pair of cropped wide legs & they are far from it. the color was also much lighter than shown in picture. super unflattering & just not for me. they're going back...                                                                                                                         1\n",
      "It's thin, very. but i were a cute scrappy athletic type bra underneath and it's so cute!\\r\\nit's a stink top, i pick a spot to tuck in around the from and let the rest flow.\\r\\naside from being a swing top, it runs large. i have 2 in xs and i'm a 34dd and i still have room.\\r\\ni have it in faded red/pink and white and am buying blue too, love it!                                                                                                                                                             1\n",
      "Love these! they are my new favorite weekend pant. they are comfortable, versatile, and cute. the fit and cut are great too. a must have for your wardrobe.                                                                                                                                                                                                                                                                                                                                                               1\n",
      "As stated in my review title, they're amazing! they're incredibly well made, have just the right amount of stretch, and are so flattering. i think the boot cut makes them look like pants rather than leggings. they can definitively be worn to work, or at least where i work, where the dress code is business casual. my only issue is the length, which being at 5'3 isn't surprising. they're about 3 inches too long. i'm a size 8-10 and got the large. i couldn't recommend these enough                        1\n",
      "I just received my duster . i love it! the coat is as pictured. the fabric is medium weight denim with some stretch. it feels like a denim coat that you have worn for years. i'm 5'8\" and the duster hits mid-calf. i'm a curvy size 14-16 and the xl fits perfectly. the only issue that might arise is that the sleeves are long; they fit me perfectly but i have long arms. this will be my new go to coat for fall.                                                                                                 1\n",
      "Very small! so disappointed! they did not even have a size for me to exchange a day later when they arrived!                                                                                                                                                                                                                                                                                                                                                                                                              1\n",
      "I'm so glad the other reviewer also found these small. literally, the largest size i have ever bought. but the style is really cute, sort of dapper british boy...                                                                                                                                                                                                                                                                                                                                                        1\n",
      "So soft and comfy.  fits great, love the length.  i am sure it will get much wear, great addition to my wardrobe.                                                                                                                                                                                                                                                                                                                                                                                                         1\n",
      "Knitted midi skirts are part of my daily uniform so i was drawn to this one. its high quality showcases intricate details: the pattern on the front is different from that on the back, the hem is asymmetric and is reverse high-low, the flat waist means the skirt is not too voluminous. the colors and pattern are reminiscent of missoni. it should be easy to coordinate with solid tops. wonderful quality and machine washable. i'm 5'5\" and the petite medium fits me as pictured. since i want the back t      1\n",
      "\"vegan suede\" makes these sound fancier than they are. i love them and they're super cozy and a nice change from plain leggings, but they're just a microfiber legging which makes the price about 20 too high even for retailer. still... i'm sure i'll wear them plenty. i usually wear a 2-4 and the xs fit me, which makes me think they'd be too large for a size 0/xs.                                                                                                                                              1\n",
      "Always get compliments when i wear these pants (my mom has the exact same pants and loves them too). they are great for work and transitioning to go out after. i like my pants tight, but these run a little small.                                                                                                                                                                                                                                                                                                      1\n",
      "This is a very cute, casual sweater. i originally ordered a size medium but i had to send it back because it was way too large all over. i recently received the size small and i'm going to keep it. it is still a roomy fit but the overall design of the sweater is a relaxed fit. the color combination and texture of this sweater is lovely.                                                                                                                                                                        1\n",
      "I usually wear a medium in jackets, took a chance with the small in this coat. it fits well, the arms are a bit snug but not too snug. beautiful design though. biggest disappointment was quality. i thought the jacket would be thick and warm. it's pretty thin, will test out warmth soon. overall decent purchase, would buy again.                                                                                                                                                                                  1\n",
      "Good quality; casual feel good dress. it can be worn as dress, or as tunic over the pants.                                                                                                                                                                                                                                                                                                                                                                                                                                1\n",
      "I love this! it is comfortable, flowing and reminds me of glamorous women in 1970's movies. i especially love that is completely looks like a shirt (its pants) because i don't have to worry about my skirt flying up as i race around the city. bra// no bra doesn't matter, which i love. as someone with a larger bottom then top and am pretty tall, i usually have trouble finding one piece items that aren't too short in the crotch/waist zone. very roomy without looking like a sack.                          1\n",
      "Bought as a gift. really soft and cozy. i am sure she will love it!                                                                                                                                                                                                                                                                                                                                                                                                                                                       1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ..\n",
      "I have been needing a rain coat and saw this one on sale, so decided to try it on. i do wish it was more \"fitted\", but it is pretty cute. the embroidered detail is nice. too bad the xs petite is sold out. i have no idea if it will hold to the rain though...                                                                                                                                                                                                                                                         1\n",
      "I like to have a capsule wardrobe for all seasons so that when i travel, or just for everyday, i have a multitude of options with a few good quality pieces. i am not a fan of 'dry clean only' items, so anything that i can find that i can at least hand wash with good results and is within my color palette and sense of style is always a great find. this light weight cardi can work for multiple seasons easily, it is a tad boxy, but it actually works for me (5'4, 34c, 125 lbs) i can wear it with a c      1\n",
      "Comfortable casual, hip. i have the black & white color which is a bit thicker than the other colors which i prefer as i recently had a baby and need a little extra fabric. i wish the fabric was a bit softer but the cut is so flattering there was no way i was sending it back. i wish the other colors were in the same thicker fabric and i would have ordered more. my new go to top. the black ribbon on the back is my favorite part.                                                                           1\n",
      "Purchased this in white specifically because i loved the back detail-- (i don't know why most designers overlook the back??). huge disappointment-- the back is totally plain, not at all like the picture of the white top on here and the fabric in the back isn't even the same material as the front. it's almost as if the back is made out of leftover lining from another garment. it was a very sad return! i usually love this brand, this was just a quality control oversight i guess.                         1\n",
      "I love the look of this bra, but unfortunately it is pretty skimpy and sheer. i need a little more padding to define my shape and i wish it had modesty padding. this wasn't for me so i returned it.                                                                                                                                                                                                                                                                                                                     1\n",
      "I am 5'2\" and 115lbs......ordered the blue motif in small petite. they were not only too big overall but were way too long. i had to roll them up several times to get the right length. because of fabric design these would definitely have to be hemmed. i had to check tag because i thought for sure i got sent a regular length but they were petite. not sure if they are worth trying in a smaller size..... pants were really comfy but maybe too pajama like for my taste.                                      1\n",
      "I think this dress is very pretty and i like that it's made of silk.  i also like the way it fits since it skims over my figure flaws without being too poufy.  what i don't like is the sloppiness of how the print was stitched on my dress.  the print frame is offset and details are cut off in both the front and back (you can see similar in the model shot from behind).  for the price i was expecting a little more quality control.  i also do not care for the lining.  i do not think the off white is      1\n",
      "Love the fit - doesn't cling to my midsection and detail on sleeves is very pretty. fits true to size.\\r\\ni got the black but want to order it in other colors as well. can be dressed up or down.                                                                                                                                                                                                                                                                                                                        1\n",
      "I was so excited to get this dress. i saw someone try it on in the store and waited all season for it to go on sale. i loved it except for the seam that was right at the neckline in the front. they didn't even try to match up the fabrics. it was so obvious and cheap looking that i had to send this dress back. so sad!                                                                                                                                                                                            1\n",
      "I like the look and fit of this shirt. can be dressed up or more casual. i got the purple motif, although i also like the brown and think that with all of the black in there (on the brown one) it would give a dressier look. i usually wear small from retailer, although this is my first blouse from this brand -- ended up getting an xs regular. i wanted the sleeves to fit at 3/4 as shown in the pics, but still be loose. i had a ton of extra room in the small, and the sleeves hit at wrist bone            1\n",
      "I have had this dress in the shopping basket on my retailer app and was dying to try it on in the store. luckily, newbury street in boston had it so i stopped by yesterday. the dress is everything i hoped and even better! the cut could not be more flattering. to get the nice, classic fit in the front, i stayed true to my usual size (4) but worried the buttons would be straining like another reviewer said. as soon as the bow in the front is tied, it keeps everything together and is very comf           1\n",
      "I ordered the navy/gray version in size xl. it fits me true to size, matching the online photos. the colors matched too. the fabric is so soft. it's warm while being lighter in weight. very comfortable. the collar wasn't bulky either. it's made to last. one of my retailer favorites.                                                                                                                                                                                                                               1\n",
      "I loved the look of this dress online, and it's everything i hoped and more in person.\\r\\ni'm 5'10\", 155# and pear-shaped.\\r\\nwhile the bottom of this dress is voluminous, it definitely did not have a pregnant fit on my body shape.\\r\\nthe length was absolutely perfect, it wasn't scratchy in the least. i got compliments on the dress all day long. wore with a pair of cowboy boots while wine tasting in napa.                                                                                                  1\n",
      "This dress is cute and comfortable. big but not too big, skimming. i usually wear a 12 pant and bought a medium and it is great. i am on the taller side and the length was great too.                                                                                                                                                                                                                                                                                                                                    1\n",
      "This dress is horrible. i can't believe they can get away with calling it a \"dress\". it should have been called a tunic or shirt. it looks like it is a soft flowing dress made out of nice material from the pictures, no way. it is made from sweatshirt material it is lifeless and is kind of stiff. it came to the top of my thighs. i can't find one nice thing to say about this dress and i do not recommend it. the picture does it so much more justice that it is worth.                                       1\n",
      "I really love this top. it looks so sweet and beautiful and is perfect for dressing up a pair of jeans. if you are on the short size it may be a little long so keep that in mind. i love it!                                                                                                                                                                                                                                                                                                                             1\n",
      "Love it! cute, flattering, and even though the material is thin - it is still very cozy. i have no complains about the quality; i haven't found any loose threads or other issues.\\r\\n\\r\\nthe cardigan runs tts. i got m instead of my usual s (because s was out of stock), and it's a little loose in the armpits. but i still like the cardigan and i'm keeping it.                                                                                                                                                    1\n",
      "Love this top! super comfortable, great fit, and really pretty colors. probably going to buy it in multiple colors it fits so great.                                                                                                                                                                                                                                                                                                                                                                                      1\n",
      "I own this shirt in dark green,\\nnavy, and white.\\nit is perfect. it drapes in such a flattering way, nice weight.\\nit shows curves in all the right ways but does not fit too snug, emphasizing every flaw.\\nand finally... the buttons are placed perfectly so that you don't have to choose between extremely conservative or way too provocative (bra showing).\\nwell done!                                                                                                                                           1\n",
      "I wear a size 4 and i ordered the small for this top. it is huge and gave me a maternity-look that i wasn't going for. i was hoping for a loose, body-skimming fit as shown on the model in the picture but that wasn't happening with this top.                                                                                                                                                                                                                                                                          1\n",
      "Beautiful white denim pants. the fit is perfect. fitted on the top with a nice flare on the bottom. very classy and versatile cut. paige denim runs long for me and these are no exception. will be getting them hemmed but i don't mind because they are perfect!                                                                                                                                                                                                                                                        1\n",
      "This dress looks way better than pictured online. it is lyocel i think so it has a little bit of weight (not heavy and bulky like denim but not as thin as some chambray items i've purchased before) and lays great! i purchased a size small, i am 5'8'' 128lbs and thought it was true to size, i can't wait to wear this! warm weather, sandals and a tote for running errands!                                                                                                                                       1\n",
      "The first day i wore this jacket to work, three people told me how great it looked. it's stylish but comfy, looks great worn with a tunic and leggings or accompanying a skirt and tights. best of all, the camel color is a great change from black and as a bonus, doesn't show my orangeish lab's dog hair!                                                                                                                                                                                                            1\n",
      "There's just the right amount of billowy grace in this dress. the fit is perfect and the material moves and breathes with you. cute with a jean jacket on chillier days too.                                                                                                                                                                                                                                                                                                                                              1\n",
      "Absolutely beautiful jacket...the craftsmanship is amazing, and the colors remind me of a impressionist water color. the jacket runs true to size (i'm 5'7\" and 115 pounds with a 30e bust and the extra small fit perfectly). unlike the other reviewers, i didn't have issue with the bottom not lying flat or the collar bunching up. i wore it with a green leather pencil skirt and suede stilettos, but you can also wear it with skinny jeans as well.i got this very deeply discounted, and although it is i      1\n",
      "I normally wear a small and sometimes a medium. even the extra small feels large all over and in the length. it's gorgeous though.                                                                                                                                                                                                                                                                                                                                                                                        1\n",
      "I ordered my typical 6 petite and found that the buttons were pulling at the bust ( i'm 34 b) and at the waist. i'm returning and ordering a size 8 petite because i'm a sucker for a shirtdress and a cute novelty print. the quality is nice and the length was perfect for my short 4\"11 frame, now only to wait for it to be shipped! oh how i wish petites were available in my local store!                                                                                                                         1\n",
      "Beautiful top that will go with anything. looking forward to wearing it.                                                                                                                                                                                                                                                                                                                                                                                                                                                  1\n",
      "I like this sweater so much i just bought it in a second color! the pleats make the sweater conform to my shape just enough to be flattering. i wore it over three different dresses this week that might have felt too bare for work or cooler weather. i live in a hot climate so this is the right weight for our cooler months. the metallic threads give it a little bit of flair and the grey color goes with everything. i'm 5'7\" size 10-12 and the large fit just right.                                         1\n",
      "Great fit, can be dressy or casual, goes with everything, i adore tis jacket!                                                                                                                                                                                                                                                                                                                                                                                                                                             1\n",
      "Length: 22634, dtype: int64\n",
      "Rating\n",
      "5    13131\n",
      "4     5077\n",
      "3     2871\n",
      "2     1565\n",
      "1      842\n",
      "dtype: int64\n",
      "Recommended IND\n",
      "1    19314\n",
      "0     4172\n",
      "dtype: int64\n",
      "Positive Feedback Count\n",
      "0      11176\n",
      "1       4043\n",
      "2       2193\n",
      "3       1433\n",
      "4        922\n",
      "5        673\n",
      "6        525\n",
      "7        374\n",
      "8        319\n",
      "9        261\n",
      "10       225\n",
      "11       178\n",
      "12       146\n",
      "14       121\n",
      "13       102\n",
      "15        94\n",
      "17        81\n",
      "16        74\n",
      "18        62\n",
      "19        54\n",
      "20        40\n",
      "23        31\n",
      "21        30\n",
      "22        29\n",
      "25        25\n",
      "28        24\n",
      "26        23\n",
      "24        21\n",
      "27        20\n",
      "30        18\n",
      "       ...  \n",
      "49         2\n",
      "46         2\n",
      "55         2\n",
      "58         2\n",
      "66         1\n",
      "50         1\n",
      "64         1\n",
      "94         1\n",
      "48         1\n",
      "98         1\n",
      "78         1\n",
      "82         1\n",
      "59         1\n",
      "93         1\n",
      "69         1\n",
      "87         1\n",
      "71         1\n",
      "54         1\n",
      "89         1\n",
      "108        1\n",
      "117        1\n",
      "122        1\n",
      "77         1\n",
      "84         1\n",
      "68         1\n",
      "52         1\n",
      "56         1\n",
      "61         1\n",
      "99         1\n",
      "95         1\n",
      "Length: 82, dtype: int64\n",
      "Division Name\n",
      "General           13850\n",
      "General Petite     8120\n",
      "Initmates          1502\n",
      "dtype: int64\n",
      "Department Name\n",
      "Tops        10468\n",
      "Dresses      6319\n",
      "Bottoms      3799\n",
      "Intimate     1735\n",
      "Jackets      1032\n",
      "Trend         119\n",
      "dtype: int64\n",
      "Class Name\n",
      "Dresses           6319\n",
      "Knits             4843\n",
      "Blouses           3097\n",
      "Sweaters          1428\n",
      "Pants             1388\n",
      "Jeans             1147\n",
      "Fine gauge        1100\n",
      "Skirts             945\n",
      "Jackets            704\n",
      "Lounge             691\n",
      "Swim               350\n",
      "Outerwear          328\n",
      "Shorts             317\n",
      "Sleep              228\n",
      "Legwear            165\n",
      "Intimates          154\n",
      "Layering           146\n",
      "Trend              119\n",
      "Casual bottoms       2\n",
      "Chemises             1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in data.columns.values:\n",
    "    print (i)\n",
    "    print (pd.value_counts(data[i].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change the data types accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['Age','Positive Feedback Count']\n",
    "categorical =['Rating','Recommended IND','Division Name','Department Name','Class Name','Clothing ID']\n",
    "string = ['Review Text','Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in numerical:\n",
    "    data[num] = data[num].astype('int64')\n",
    "    \n",
    "for cat in categorical:\n",
    "    data[cat] = data[cat].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23486.0</td>\n",
       "      <td>23486.000000</td>\n",
       "      <td>19676</td>\n",
       "      <td>22641</td>\n",
       "      <td>23486.0</td>\n",
       "      <td>23486.0</td>\n",
       "      <td>23486.000000</td>\n",
       "      <td>23472</td>\n",
       "      <td>23472</td>\n",
       "      <td>23472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1206.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13993</td>\n",
       "      <td>22634</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1078.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love it!</td>\n",
       "      <td>Perfect fit and i've gotten so many compliment...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1024.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>13131.0</td>\n",
       "      <td>19314.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13850</td>\n",
       "      <td>10468</td>\n",
       "      <td>6319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>43.198544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.535936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12.279544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.702202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Clothing ID           Age     Title  \\\n",
       "count       23486.0  23486.000000     19676   \n",
       "unique       1206.0           NaN     13993   \n",
       "top          1078.0           NaN  Love it!   \n",
       "freq         1024.0           NaN       136   \n",
       "mean            NaN     43.198544       NaN   \n",
       "std             NaN     12.279544       NaN   \n",
       "min             NaN     18.000000       NaN   \n",
       "25%             NaN     34.000000       NaN   \n",
       "50%             NaN     41.000000       NaN   \n",
       "75%             NaN     52.000000       NaN   \n",
       "max             NaN     99.000000       NaN   \n",
       "\n",
       "                                              Review Text   Rating  \\\n",
       "count                                               22641  23486.0   \n",
       "unique                                              22634      5.0   \n",
       "top     Perfect fit and i've gotten so many compliment...      5.0   \n",
       "freq                                                    3  13131.0   \n",
       "mean                                                  NaN      NaN   \n",
       "std                                                   NaN      NaN   \n",
       "min                                                   NaN      NaN   \n",
       "25%                                                   NaN      NaN   \n",
       "50%                                                   NaN      NaN   \n",
       "75%                                                   NaN      NaN   \n",
       "max                                                   NaN      NaN   \n",
       "\n",
       "        Recommended IND  Positive Feedback Count Division Name  \\\n",
       "count           23486.0             23486.000000         23472   \n",
       "unique              2.0                      NaN             3   \n",
       "top                 1.0                      NaN       General   \n",
       "freq            19314.0                      NaN         13850   \n",
       "mean                NaN                 2.535936           NaN   \n",
       "std                 NaN                 5.702202           NaN   \n",
       "min                 NaN                 0.000000           NaN   \n",
       "25%                 NaN                 0.000000           NaN   \n",
       "50%                 NaN                 1.000000           NaN   \n",
       "75%                 NaN                 3.000000           NaN   \n",
       "max                 NaN               122.000000           NaN   \n",
       "\n",
       "       Department Name Class Name  \n",
       "count            23472      23472  \n",
       "unique               6         20  \n",
       "top               Tops    Dresses  \n",
       "freq             10468       6319  \n",
       "mean               NaN        NaN  \n",
       "std                NaN        NaN  \n",
       "min                NaN        NaN  \n",
       "25%                NaN        NaN  \n",
       "50%                NaN        NaN  \n",
       "75%                NaN        NaN  \n",
       "max                NaN        NaN  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23486 entries, 0 to 23485\n",
      "Data columns (total 10 columns):\n",
      "Clothing ID                23486 non-null category\n",
      "Age                        23486 non-null int64\n",
      "Title                      19676 non-null object\n",
      "Review Text                22641 non-null object\n",
      "Rating                     23486 non-null category\n",
      "Recommended IND            23486 non-null category\n",
      "Positive Feedback Count    23486 non-null int64\n",
      "Division Name              23472 non-null category\n",
      "Department Name            23472 non-null category\n",
      "Class Name                 23472 non-null category\n",
      "dtypes: category(6), int64(2), object(2)\n",
      "memory usage: 945.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observe that Review Text,Title,Division Name, Department Name and Class Name has null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify missing value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clothing ID                   0\n",
       "Age                           0\n",
       "Title                      3810\n",
       "Review Text                 845\n",
       "Rating                        0\n",
       "Recommended IND               0\n",
       "Positive Feedback Count       0\n",
       "Division Name                14\n",
       "Department Name              14\n",
       "Class Name                   14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop all the rows having Na's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clothing ID                0\n",
       "Age                        0\n",
       "Title                      0\n",
       "Review Text                0\n",
       "Rating                     0\n",
       "Recommended IND            0\n",
       "Positive Feedback Count    0\n",
       "Division Name              0\n",
       "Department Name            0\n",
       "Class Name                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna(axis=0)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the unique levels in Clothing ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1095"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clothing_ID_levels = np.size(np.unique(data['Clothing ID'], return_counts=True)[0])\n",
    "clothing_ID_levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove ClothingID and Target attribute from Categorical data for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Recommended IND', 'Division Name', 'Department Name', 'Class Name'], dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_attr = data.select_dtypes('category').columns\n",
    "categorical_attr = categorical_attr.drop(['Rating','Clothing ID'])\n",
    "categorical_attr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_attr = 'Rating'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-procressing of numerical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert integer to float ( useful for standardization further)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_attr = data.select_dtypes('int64').columns\n",
    "numerical_df = data[numerical_attr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>49.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Positive Feedback Count\n",
       "2  60.0                      0.0\n",
       "3  50.0                      0.0\n",
       "4  47.0                      6.0\n",
       "5  49.0                      4.0\n",
       "6  39.0                      1.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_df=numerical_df.astype('float')\n",
    "numerical_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_categorical_train, data_categorical_test, \\\n",
    "data_numerical_train, data_numerical_test, \\\n",
    "data_string_train, data_string_test, \\\n",
    "data_clothingID_train, data_clothingID_test, \\\n",
    "Y_train, Y_test = train_test_split(data[categorical_attr],\n",
    "                                   numerical_df,\n",
    "                                   data[string],\n",
    "                                   data['Clothing ID'],\n",
    "                                   data[target_attr],\n",
    "                                   test_size=0.33, random_state=123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3394</th>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19794</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4534</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22350</th>\n",
       "      <td>44.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8586</th>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3536</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15640</th>\n",
       "      <td>45.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4663</th>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10230</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9931</th>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22593</th>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510</th>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14664</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22667</th>\n",
       "      <td>55.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20192</th>\n",
       "      <td>33.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13345</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8178</th>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6100</th>\n",
       "      <td>47.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4302</th>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19424</th>\n",
       "      <td>49.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18160</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8645</th>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>39.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3816</th>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16403</th>\n",
       "      <td>63.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2813</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14204</th>\n",
       "      <td>40.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21224</th>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3929</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9613</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20945</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7944</th>\n",
       "      <td>37.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23484</th>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19614</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7743</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15215</th>\n",
       "      <td>46.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21778</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9564</th>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20858</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17860</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4014</th>\n",
       "      <td>62.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3509</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21203</th>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4194</th>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6767</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16069</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9281</th>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18366</th>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21180</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18788</th>\n",
       "      <td>51.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13173 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Positive Feedback Count\n",
       "3394   46.0                      1.0\n",
       "3720   48.0                      0.0\n",
       "1036   82.0                      0.0\n",
       "19794  48.0                      0.0\n",
       "4534   30.0                      0.0\n",
       "22350  44.0                     29.0\n",
       "8586   26.0                      1.0\n",
       "3536   34.0                      0.0\n",
       "15640  45.0                      4.0\n",
       "4663   48.0                      2.0\n",
       "10230  22.0                      0.0\n",
       "9931   49.0                      0.0\n",
       "22593  53.0                      2.0\n",
       "3510   39.0                      1.0\n",
       "292    65.0                      0.0\n",
       "14664  22.0                      1.0\n",
       "22667  55.0                     19.0\n",
       "20192  33.0                      3.0\n",
       "13345  46.0                      0.0\n",
       "8178   43.0                      0.0\n",
       "6100   47.0                      3.0\n",
       "4302   43.0                      0.0\n",
       "19424  49.0                      3.0\n",
       "18160  33.0                      0.0\n",
       "8645   47.0                      2.0\n",
       "7996   34.0                      1.0\n",
       "4000   39.0                      3.0\n",
       "238    63.0                      0.0\n",
       "3816   53.0                      1.0\n",
       "16403  63.0                      6.0\n",
       "...     ...                      ...\n",
       "2813   55.0                      1.0\n",
       "14204  40.0                     10.0\n",
       "21224  61.0                      1.0\n",
       "3929   35.0                      0.0\n",
       "9613   37.0                      0.0\n",
       "2922   52.0                      0.0\n",
       "5048   39.0                      0.0\n",
       "20945  25.0                      0.0\n",
       "7944   37.0                      4.0\n",
       "23484  28.0                      2.0\n",
       "19614  36.0                      0.0\n",
       "7743   41.0                      0.0\n",
       "15215  46.0                     23.0\n",
       "21778  27.0                      0.0\n",
       "9564   64.0                      2.0\n",
       "20858  24.0                      0.0\n",
       "17860  39.0                      0.0\n",
       "4014   62.0                      3.0\n",
       "3509   28.0                      0.0\n",
       "21203  36.0                      3.0\n",
       "4194   59.0                      0.0\n",
       "146    39.0                      0.0\n",
       "1148   38.0                      2.0\n",
       "6767   42.0                      0.0\n",
       "125    34.0                      1.0\n",
       "16069  39.0                      0.0\n",
       "9281   53.0                      1.0\n",
       "18366  49.0                      0.0\n",
       "21180  45.0                      0.0\n",
       "18788  51.0                     23.0\n",
       "\n",
       "[13173 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_numerical_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert categorical attributes to numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore option is used to ignore if an unknown categorical feature is\n",
    "present during transform instead of raising error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(handle_unknown='ignore' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'General'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-17c9d09619e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mOneHotEncoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehotencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_categorical_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py35tf1/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1954\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m         \"\"\"\n\u001b[0;32m-> 1956\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1957\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35tf1/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   2017\u001b[0m         \"\"\"\n\u001b[1;32m   2018\u001b[0m         return _transform_selected(X, self._fit_transform,\n\u001b[0;32m-> 2019\u001b[0;31m                                    self.categorical_features, copy=True)\n\u001b[0m\u001b[1;32m   2020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2021\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35tf1/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36m_transform_selected\u001b[0;34m(X, transform, selected, copy)\u001b[0m\n\u001b[1;32m   1807\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msparse\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m     \"\"\"\n\u001b[0;32m-> 1809\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mselected\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35tf1/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'General'"
     ]
    }
   ],
   "source": [
    "OneHotEncoder = onehotencoder.fit(data_categorical_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "transform() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-cd9b90d40e2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mOneHotEncoder_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_categorical_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mOneHotEncoder_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_categorical_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: transform() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "OneHotEncoder_train = OneHotEncoder.transform(data_categorical_train).toarray()\n",
    "OneHotEncoder_test = OneHotEncoder.transform(data_categorical_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6489, 30)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OneHotEncoder_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of Target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5, 2, 4, 1]\n",
       "Categories (5, int64): [3, 5, 2, 4, 1]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_levels=len(data['Rating'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are 5 different levels in the Target Rating , we need to one hot encode so that no order is implied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneHotEncoder = onehotencoder.fit(Y_train.values.get_values().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneHotEncoder_target_train = OneHotEncoder.transform(Y_train.values.get_values().reshape(-1, 1)).toarray()\n",
    "OneHotEncoder_target_test = OneHotEncoder.transform(Y_test.values.get_values().reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6489, 5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OneHotEncoder_target_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scalar= MinMaxScaler()\n",
    "scaled_attr = Scalar.fit(data_numerical_train)\n",
    "scaled_attr_train= scaled_attr.transform(data_numerical_train)\n",
    "scaled_attr_test= scaled_attr.transform(data_numerical_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60493827, 0.        ],\n",
       "       [0.20987654, 0.        ],\n",
       "       [0.08641975, 0.        ],\n",
       "       ...,\n",
       "       [0.27160494, 0.        ],\n",
       "       [0.18518519, 0.07407407],\n",
       "       [0.51851852, 0.02777778]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_attr_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stack both numerical and Categorical feautures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13173, 32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.hstack((scaled_attr_train, OneHotEncoder_train))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing of Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing of Review Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the length of the text having maximum number of occurances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the unique count of text length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_elements, counts_elements = np.unique(data_string_train['Review Text'].apply(len),return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9,  12,  13,  15,  16,  17,  20,  22,  24,  25,  26,  27,  28,\n",
       "        29,  30,  31,  32,  33,  35,  36,  37,  38,  39,  40,  41,  42,\n",
       "        43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "        56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
       "        69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
       "        82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
       "        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
       "       108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
       "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
       "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
       "       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,\n",
       "       160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172,\n",
       "       173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,\n",
       "       186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
       "       199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
       "       212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
       "       225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
       "       238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250,\n",
       "       251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
       "       264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276,\n",
       "       277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289,\n",
       "       290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302,\n",
       "       303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315,\n",
       "       316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328,\n",
       "       329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341,\n",
       "       342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354,\n",
       "       355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
       "       368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380,\n",
       "       381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393,\n",
       "       394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
       "       407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
       "       420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432,\n",
       "       433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445,\n",
       "       446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458,\n",
       "       459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471,\n",
       "       472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484,\n",
       "       485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497,\n",
       "       498, 499, 500, 501, 502, 503, 504, 506, 507, 508])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    1,    1,    1,    1,    3,    2,    1,    3,    3,    1,\n",
       "          4,    2,    2,    2,    4,    1,    1,    2,    1,    4,    1,\n",
       "          4,    2,    3,    2,    3,    4,    2,    6,    4,    2,    4,\n",
       "         16,   11,    7,    8,   12,   13,    9,    9,    9,   10,   12,\n",
       "         14,    9,    9,   12,   12,   19,   15,   16,   20,   15,   17,\n",
       "         24,   25,   11,   10,   18,   11,   12,   13,   18,   15,   23,\n",
       "         22,   18,   10,   14,   17,   16,   12,   26,   16,   17,   23,\n",
       "         18,   18,   12,   18,   19,   15,   30,   29,   19,   22,   15,\n",
       "         17,   20,   15,   23,   23,   16,   30,   15,   29,   16,   21,\n",
       "         24,   16,   21,   22,   24,   23,   24,   25,   26,   25,   25,\n",
       "         22,   21,   28,   23,   26,   28,   27,   24,   21,   19,   24,\n",
       "         29,   28,   24,   28,   26,   23,   26,   22,   27,   26,   20,\n",
       "         23,   33,   17,   26,   23,   18,   39,   18,   21,   39,   17,\n",
       "         28,   30,   28,   26,   24,   31,   31,   29,   26,   29,   30,\n",
       "         21,   24,   23,   26,   26,   28,   31,   25,   24,   30,   29,\n",
       "         33,   24,   27,   34,   18,   29,   27,   29,   26,   28,   32,\n",
       "         30,   25,   25,   20,   23,   30,   40,   31,   35,   28,   25,\n",
       "         32,   25,   25,   27,   38,   26,   30,   33,   31,   37,   34,\n",
       "         23,   32,   26,   29,   24,   38,   28,   32,   26,   29,   44,\n",
       "         30,   30,   30,   30,   29,   32,   19,   33,   23,   29,   31,\n",
       "         29,   22,   35,   30,   31,   25,   25,   24,   20,   27,   28,\n",
       "         28,   24,   25,   30,   32,   28,   40,   22,   31,   33,   26,\n",
       "         24,   17,   34,   25,   35,   28,   23,   33,   31,   33,   38,\n",
       "         35,   28,   24,   23,   39,   28,   26,   26,   32,   21,   21,\n",
       "         24,   23,   27,   28,   24,   30,   28,   26,   26,   30,   27,\n",
       "         23,   27,   21,   31,   27,   30,   28,   24,   25,   34,   32,\n",
       "         32,   23,   24,   29,   35,   25,   35,   24,   22,   28,   23,\n",
       "         28,   28,   30,   31,   31,   17,   25,   28,   21,   21,   27,\n",
       "         24,   20,   39,   31,   30,   28,   22,   30,   26,   35,   25,\n",
       "         25,   26,   18,   23,   18,   20,   23,   29,   31,   21,   25,\n",
       "         28,   23,   26,   27,   16,   23,   23,   29,   18,   20,   28,\n",
       "         16,   17,   29,   21,   20,   21,   27,   18,   30,   21,   32,\n",
       "         21,   26,   21,   23,   17,   27,   10,   18,   16,   29,   27,\n",
       "         22,   13,   24,   24,   23,   25,   16,   15,   17,   16,   17,\n",
       "         21,   18,   20,   23,   32,   21,   13,   22,   24,   20,   23,\n",
       "         24,   21,   23,   23,   14,   17,   28,   17,   23,   18,   15,\n",
       "         15,   12,   18,   19,   23,   33,   14,   16,    9,   17,   14,\n",
       "         19,   17,   17,   19,   16,   18,   11,   12,   13,   23,   21,\n",
       "         11,   15,   23,   23,   23,   21,   21,   17,   20,   19,   22,\n",
       "         14,   21,   22,   12,   15,   17,   13,   15,   24,   17,   16,\n",
       "         18,    9,   16,   12,   16,   11,   12,   15,   26,   13,   13,\n",
       "         19,   15,   17,   21,   15,   16,   16,   13,   15,   11,   21,\n",
       "         18,   23,   21,   16,   10,   17,   13,   18,   13,   19,   15,\n",
       "         16,    9,   21,   13,   32,   92,   23,   20,   11,  488, 1927,\n",
       "         71,  270,    8,   22,    1,    1,    1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We observe that the highest value of count is 1927 and the corresponding text length is 500 , hence we are choosing 500 as the maximum text length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_text_count_length = list(counts_elements).index(max(counts_elements))\n",
    "REVIEW_TEXT_MAX_SEQUENCE_LENGTH = unique_elements[max_text_count_length]\n",
    "REVIEW_TEXT_MAX_SEQUENCE_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11986 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(oov_token='None')\n",
    "tokenizer.fit_on_texts(data_string_train['Review Text'])\n",
    "review_text_train = tokenizer.texts_to_sequences(data_string_train['Review Text'])\n",
    "review_text_test = tokenizer.texts_to_sequences(data_string_test['Review Text'])\n",
    "\n",
    "word_index_review_text = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index_review_text))\n",
    "NUM_WORDS_REVIEW_TEXT = len(word_index_review_text)+1\n",
    "\n",
    "review_text_seq_train = pad_sequences(review_text_train, maxlen=REVIEW_TEXT_MAX_SEQUENCE_LENGTH)\n",
    "review_text_seq_test = pad_sequences(review_text_test, maxlen=REVIEW_TEXT_MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load the GloVe word embedding file into memory as a dictionary of word to embedding array.\n",
    "\n",
    "__Note__: Filter the embedding for the unique words in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('glove.6B.50d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, create a matrix of one embedding for each word in the training dataset. We can do that by enumerating all unique words in the Tokenizer.word_index and locating the embedding weight vector from the loaded GloVe embedding.\n",
    "\n",
    "#### The result is a matrix of weights only for words we will see during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also count the number of words not present in the glove to decide whether we need to train or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "review_embedding_matrix = np.zeros((NUM_WORDS_REVIEW_TEXT,50))\n",
    "review_word_not_in_glove_count = 0\n",
    "review_word_not_in_glove =[]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        review_embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        review_word_not_in_glove.append(word)\n",
    "        review_word_not_in_glove_count = review_word_not_in_glove_count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.41800001  0.24968    -0.41242    ... -0.18411    -0.11514\n",
      "  -0.78580999]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.17242    -0.086107   -0.78268999 ... -1.3312      0.36011001\n",
      "  -0.26620001]\n",
      " [ 0.40204    -2.33529997  0.22948    ...  0.81226999 -0.63955998\n",
      "   0.76555002]]\n"
     ]
    }
   ],
   "source": [
    "print(review_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['None', \"it's\", \"i'm\", '\\r', \"don't\", \"didn't\", \"doesn't\", \"can't\", \"i've\", \"wasn't\", \"5'4\", \"isn't\", \"i'd\", \"5'3\", \"5'5\", \"couldn't\", \"that's\", \"5'2\", \"5'7\", \"i'll\", 'xxs', \"you're\", \"5'8\", \"wouldn't\", \"5'6\", \"they're\", 'pilcro', \"5'\", \"won't\", \"5'1\", \"there's\", \"5'9\", \"haven't\", '34d', \"5'10\", \"aren't\", '36d', \"you'll\", 'xsp', '0p', '34dd', '36dd', \"would've\", '135lbs', 'xxsp', '120lbs', '30dd', \"weren't\", \"you'd\", \"it'll\", \"retailer's\", '32dd', '00p', 'xsmall', '130lbs', '140lbs', 'tshirt', '125lbs', \"5'0\", 'skinnies', '115lbs', \"5'11\", \"shouldn't\", \"they'd\", \"could've\", \"model's\", \"what's\", \"hadn't\", '110lbs', 'pxs', 'jsut', \"it'd\", '145lbs', \"70's\", \"5'4''\", 'armhole', \"you've\", '34ddd', 'cartonnier', \"they'll\", 'deletta', \"she's\", '36ddd', 'skort', 'jeggings', 'heathered', 'bralette', \"one's\", \"year's\", \"here's\", '34f', '100lbs', '34g', \"dind't\", \"6'\", '128lbs', \"let's\", '150lbs', 'skinnys', 'pxxs', '105lbs', 'pilcros', '32ddd', \"they've\", \"60's\", 'snugger', '34aa', 'stevies', \"should've\", \"we'll\", \"5'8''\", '30d', 'antho', 'xspetite', \"50's\", 'blousey', 'marled', '160lbs', 'wld', '160lb', 'antro', \"5'7'\", 'flowey', '130lb', 'regualr', \"4'11\", '109lbs', \"reviewer's\", \"mother's\", 'poofed', 'pilco', \"5'5''\", 'elevenses', 'ahve', \"hasn't\", 'backorder', '120lb', 'pointelle', \"40's\", 'colorway', 'flatering', 'colros', \"dress's\", \"4'\", \"we're\", '32g', '127lbs', '170lbs', \"husband's\", '5ft2in', '123lbs', \"5'2''\", 'rouching', 'petitie', '103lbs', \"sister's\", \"5'6''\", \"5'1''\", \"5'5'\", 'versitile', 'bagginess', '138lbs', \"valentine's\", \"anyone's\", 'htis', 'soooooo', '145lb', '36g', \"women's\", 'favs', '107lbs', \"80's\", 'seafolly', \"who's\", 'antrho', 'overdress', 'slub', \"5'3ish\", 'comf', 'flowly', '125lb', '155lbs', 'backordered', '140lb', 'supima', 'derriã¨re', '112lbs', 'racerback', \"3'\", 'camis', \"men's\", '117lbs', '32h', \"levi's\", 'siz', '37ish', 'colorways', 'htey', 'sotre', \"5'3'\", \"friend's\", '124lbs', \"5'7''\", \"woman's\", 'falttering', 'comfiest', 'wayyy', \"5'3''\", \"daughter's\", \"maeve's\", '118lbs', 'moulinette', \"pj's\", \"7'\", 'wearings', 'bodycon', \"t's\", \"30's\", 'poofing', 'reccomend', \"child's\", \"skinny's\", 'detial', \"5'0''\", 'pilcrow', \"'red'\", '0r', \"8's\", 'swtr', 'waaaaay', 'balloony', 'torsoed', 'slenderizing', '38d', 'dresse', \"manufacturer's\", \"fit's\", '116lbs', \"'s'\", \"season's\", 'buttondown', \"5'9''\", 'amterial', 'appliquã©', 'scratchiness', \"5'10''\", 'stiching', 'htem', 'sweatercoat', 'cowlneck', 'cupro', \"fabric's\", \"5'9'\", 'sacklike', 'sleev', 'eptite', 'imho', 'leggins', 'prett', 'me\\r', 'midweight', 'dresss', \"grandma's\", 'flowiness', \"stevie's\", 'lyocell', 'appliquã©s', 'underslip', \"'m'\", 'summ', 'ordere', \"reviewers'\", 'bralettes', \"son's\", 'paquerette', \"don'\", '135lb', 'waaay', \"top's\", \"2'\", \"cami's\", \"dress'\", \"mom's\", \"it'\", 'crepey', '165lbs', 'slouchier', 'smaill', 'i\\r', 'preggers', 'exmaple', 'bluishgreen', \"5''3\", 'carissima', 'petitte', \"others'\", '110lb', 'jeera', '155lb', '116lb', '175lbs', 'unseamed', '129lbs', 'preggo', 'druzy', 'delicates', 'sandles', \"else's\", 'bodytype', 'boxiness', 'expe', '107lb', 'slubby', 'whiskering', '122lbs', 'colorblock', '148lbs', \"y'all\", \"5'8'\", 'umph', 'appliquã©d', 'grea', \"children's\", \"1940's\", \"might've\", \"5''\", \"31's\", 'otk', 'poofiness', 'nicel', 'absolutly', 'perfe', 'toget', 'colr', \"6'2\", 'pricepoint', 'scratchier', 'aize', \"can'\", 'crosswrap', \"'4\", 'stretchier', 'really\\r', 'thinnish', 'howeve', 'washability', 'loompa', 'colorwise', 'stretchiness', 'bday', 'neede', \"4''\", '29p', 'unco', 'fabr', 'flatttering', \"'swing'\", \"people's\", 'mazing', \"day's\", 'snugness', 'wayyyy', 'absolutley', \"v's\", '127lb', 'offwhite', 'styl', 'uncuffed', \"pullover's\", 'alittle', 'liekd', \"1'\", 'fiancã©', 'comfotable', 'risquã©', 'batwings', 'boatneck', 'sizi', 'boyleg', 'versat', 'the\\r', 'clinged', \"28's\", \"27's\", 'unattractively', 'volumous', 'staticky', \"sweater's\", '36aa', '146lbs', 'cheekier', \"32d's\", '128lb', 'fairisle', '6petite', \"to'\", 'tenty', 'shirring', \"who've\", \"brother's\", 'underneat', 'skintone', 'linin', 'lightwei', '36h', '11inches', 'm\\r', \"'t\", 'hink', \"jean's\", '38dd', 'retu', 'handwash', 'dryel', 'highwaisted', '28dd', 'hemstitch', 'unfortunatly', 'tennies', '102lbs', 'legnth', 'colorfast', '38in', 'especia', 'reall', \"that'd\", 'onsie', \"ag's\", \"charlie's\", \"5'4'\", '106lbs', \"2''\", \"we'd\", 'comfrotable', \"29'\", 'sheerest', 'chrolox', 'altho', 'sandels', 'stretc', '30f', '34dddd', 'throu', \"material's\", \"lot's\", 'bloused', \"rec'd\", \"nephew's\", \"someone's\", 'recomme', \"wasn'\", 'it\\r', 'inseams', 'swea', '95lbs', 'undernea', 'looove', 'pilcos', \"to's\", 'purcha', 'petties', 'embroiding', 'defin', 'sleevless', 'thickish', \"joe's\", '0petite', \"today's\", 'tyhlo', 'silouette', 'cehst', '2petite', \"5'11''\", 'becau', 'rediculously', 'taylored', 'greige', '114lbs', 'top\\r', 'huuuge', '144lbs', 'walzing', 'ehhh', 'xsm', \"zoolander's\", 'embroiderey', 'knuc', 'indul', 'glimmery', 'neccissarily', 'uncomfy', 'fillerup', 'oatmealish', 'unsewn', 'sheerer', 'herls', 'nuce', 'colters', 'objectionably', 'bohemain', 'dryclean', 'refernce', 'jegging', 'korkease', 'gemline', 'formalness', 'dowton', \"'stitch'\", \"cutesy'\", \"lars'\", 'coutour', 'wrardrobe', 'delicate\\r', 'neckhole', '183lbs', 'importatn', 'matieral', 'comfortbale', 'hwoever', 'ilfelt', 'seychelle', '105lb', 'flatteri', 'delish', 'knakis', 'unadjustable', \"neckline's\", 'flatforms', 'workw', 'mutliple', 'upsize', \"'sheds'\", 'because\\r', 'fun\\r', 'stitc', \"world's\", 'layi', \"'wear\", \"out'\", 'realllllly', 'heathery', \"'cuz\", \"m'l\", 'buttondowns', 'tylho', 'retailerpolgie', \"'dry\", \"only'\", 'imlove', \"din't\", 'lightwash', 'daker', 'peitte', 'dressi', 'jewlery', 'cappier', 'tranforms', 'pommed', 'nbut', 'rahter', 'forh', \"hasn'\", \"mayn't\", 'shirter', 'xxxxxxxxs', \"'flow'\", 'slig', 'loooks', \"doe'n'tt\", 'htough', 'greay', 'lcan', 'experie', \"where'd\", 'defe', 'wansup', 'tendd', 'midwe', 'demential', 'neckband', 'throughou', 'priviledge', 'tryi', 'syllish', 'prefe', '4115', '136lbs', \"5'10'\", 'middi', '140ish', 'nijar', 'enamor', 'retailerpligie', \"'almost'\", '112lb', \"'tunic\", 'lbds', 'ulitimately', '34e', 'kne', 'sutble', 'easilly', 'smedium', 'aaaaaaamazing', 'howeverl', 'transpa', '130pounds', 'casua', 'aprã¨s', 'otth', \"stink'n\", \"'glide'\", \"'easy'\", 'biggish', 'suuuuper', 'iliked', 'weddi', \"chino's\", 'beigey', 'embroarding', 'flufff', 'untanned', 'acutually', 'alined', \"2's\", \"4's\", 'hypen', 'xlarge', 'impr', 'gorjuss', 'yoself', '195lbs', 'round\\r', \"'off\", \"shoulder'\", 'normaly', 'calter', 'thoug', 'embroi', 'owend', 'recom', 'dressied', 'definetely', 'guazy', 'dongre', 'coffe', 'piece\\r', \"ii've\", \"'slim\", \"tailored'\", 'bity', '132lbs', 'boodie', '0in', \"34g's\", 'fuzzes', 'recommemd', \"denim'\", \"'tent'\", \"'trapeze'\", 'swisuit', 'rusching', 'loun', 'versital', 'reseam', '20lb', \"'body\", \"skimming'\", 'flowinng', 'sympath', \"'fitted'\", \"40''\", 'reeeeally', 'grrrrr8', 'trired', 'lvoed', 'normall', 'availab', \"daughter'\", 'coobie', 'ecept', \"lady's\", 'brigh', \"catalog's\", 'flirtiness', 'sjut', 'braod', 'deceided', 'seriosu', 'purcahses', 'apttenrs', 'repellar', 'big\\r', 'stiff\\r', 'uuuuggghhh', 'favulous', 'defini', \"4'9\", '118lb', 'versitle', \"i''m\", 'tjhis', 'petities', 'underdress', 'xsp\\r', 'xxs\\r', 'xxsp\\r', 'peiople', 'forgivin', 'tushy', 'skiny', 'scandy', 'greyed', 'oompaloompa', 'wante', 'shrinking\\r', 'anoth', 'bismal', 'flattereing', \"24''\", 'isth', 'cheezy', \"'look'\", 'beautifull', 'whihc', 'hahahaha', 'incalled', 'reallllly', 'rehersal', 'beautifil', 'possi', 'purcahse', 'striked', 'orginially', 'palced', 'appropirate', 'opinion0', 'peite', 'gabardia', 'lacausa', 'overa', \"sundry's\", 'ilove', \"'lacy'\", \"1990's\", 'dressey', 'waiste', 'elongatesy', 'layes', 'cardis', 'angelinas', 'ansy', 'beautful', 'vinta', 'bootles', 'perfer', \"merchants'\", 'camoflauges', 'materil', 'ocol', \"we've\", 'detaling', 'fabiric', 'beaufully', 'goodone', 'mjuch', 'twinsies', 'reshipped', 'you\\r', 'boobage', 'salesgirls', 'verstaile', 'longwaisted', 'reticketed', '8petite', 'popback', 'bronzey', \"44's\", 'restocks', 'pbly', 'chestier', 'lusciousness', 'plcro', \"'2\", 'ankl', \"1920's\", 'gambl', \"individual's\", 'retailerpolgy', 'sateens', 'billowly', 'lbs\\r', '32c\\r', 'alst', 'smae', 'ddresses', 'aprts', 'tallish', 'veratile', \"money's\", \"'nubby'\", 'askedher', \"dones't\", 'nonte', 'sholulder', 'of\\r', 'sctrachy', 'suddently', 'onlin', 'jsutice', 'percect', 'lvoe', 'yfit', 'styllsit', 'insiting', 'lstretch', 'wintergreens', 'loooooove', 'tiokeep', 'embarassingly', 'accessorizes', \"'v'\", '3xs', \"'nice'\", \"'true\", \"size'\", \"pomona's\", 'sprea', '9lower', 'lbsm', 'loungey', 'chamomix', 'thickeness', 'lowcut', 'flattering1', 'freepeople', 'geeze', 'epite', 'actualyl', \"it''s\", 'petite\\r', 'witing', 'deff', 'beardedlady', 'airly', 'plico', '4yrs', 'received\\r', 'loose\\r', 'comforta', 'frumpier', 'ligher', \"26's\", 'xxxxs', 'digan', \"i'\\r\", '38f', 'compliements', 'compliement', \"junior's\", 'pefect', 'amking', 'snatc', 'xxxl', '10mths', 'bejewels', 'ummmmm', 'airyness', \"am5'4'\", \"seinfeld's\", \"must've\", 'tshirts', 'akward', '143lbs', \"retailerpolgies'\", 'imay', '125ish', 'uncuff', 'comjfortable', 'areturn', 'deminished', 'lengt', 'bootees', 'modcloth', 'differnt', 'furthe', \"havne't\", \"arm's\", 'shapelier', 'pettte', 'coored', 'uiu', \"girlfriends'\", 'whyyyyyyyyyyy', 'incred', 'garmets', 'a9dn', 'sizw', '6r', 'flipp', 'taupey', \"'peeks'\", 'tyically', '3was', 'flatte', '136lb', \"6'1\", \"'yes'\", 'definelty', 'recd', \"'warm\", \"pullover'\", \"pantie's\", 'grapeish', 'aaaahs', \"'flare'\", 'desperat', \"city's\", \"'shear\", '6t', 'puctures', 'mosly', 'loooooong', 'edgey', 'linty', 'unfini', \"20's\", 'reviewwers', 'lowness', \"isn'\", \"'p\", 'sisz', 'loely', 'buttoms', 'elastized', 'sooooooooooooooo', 'silh', 'embroid', 'wotb', \"'green'\", 'sillhoette', \"there'd\", '123lbssize', \"wearer's\", 'outlin', \"ann's\", \"'details'\", 'occas', 'diagnol', 'sofy', 'nexk', 'rehemmed', 'ordinar', 'lapels\\r', \"it's\\r\", 'to\\r', \"'poor\", \"boy'\", 'somethig', 'shapelessly', 'sllm', \"winter's\", 'disappoitned', \"models'\", \"sleeves'\", 'beauitiful', 'drappiness', 'boobed', 'juuuuussst', 'camos', 'litttle', '2fit', 'rouched', 'negativ', '4inches', 'comfortabl', 'recommen', '150lb', 'triue', 'poochy', 'maternit', 'delettas', 'wayup', 'non0muscular', '9inches', 'gauzey', 'comfortab', 'crimplene', 'spacedye', 'unbeliev', 'looged', \"grandpa's\", \"niece's\", 'flowier', 'lurve', 'espradilles', 'instagrams', 'nonsolid', \"'belt'\", \"'tuck'\", 'chicness', 'mildish', 'flouncier', \"lapel's\", \"fisher's\", 'revieved', 'actuallly', 'hopefulluy', 'choosi', \"36'\", 'asscoaites', 'maintena', 'acrossed', \"'long\", \"heavy'\", \"'go\", 'althetic', 'anticpated', 'someth', 'vousta', 'cinchable', 'disapointed', 'marvilously', 'swishier', 'pregant', '0verall', \"'cut'\", \"'tattered\", \"'cuts\", 'polkadots', 'hipline', \"'comfort\", \"zone'\", 'inkish', '172lbs', 'vaired', 'additio', '4fits', \"'maybe'\", 'wowza', 'laec', \"'teeny\", \"bop'\", \"purchaser's\", 'rinestones', '20lbs', 'darkler', 'mathced', 'everythiing', 'prefectly', 'msallet', 'jkeep', 'matvehd', 'ejans', 'wildberry', 'qualit', 'lyocel', 'trapezey', \"ap's\", \"twinkle's\", '98lbs', 'contralaterally', \"weather's\", 'denimy', 'hourgass', \"pant's\", 'howev', 'alllll', 'completel', 'upsid', 'admirin', 'bottons', 'cutr', 'wiskering', 'bailley', 'incase', 'colorsblocking', 'liittle', 'pregnan', 'cut\\r', 'neckline\\r', 'skin\\r', 'thread\\r', 'thorwback', \"'i'm\", 'tanktop', \"3000's\", 'denium', 'ghis', 'probabley', \"print's\", \"girl's\", 'narrowis', 'easil', 'wrin', \"nobody's\", 'yest', 'awakward', 'buldging', 'myuch', 'disppaointed', 'whte', '8yo', 'shyle', '38dds', 'purpley', 'skir', 'fast\\r', '34ff', 'descri', 'but\\r', \"rosemary's\", 'breakthable', 'choise', 'bcup', '114lb', 'puckery', \"kind've\", 'cutewith', 'bootcut', '03dd', 'shapel', 'dressiness', 'am5', \"'3\", 'been\\r', 'calsual', 'shiryt', 'lingere', 'seciton', 'athleisure', 'xxxs', 'lthink', 'ebough', 'embrodering', 'hifh', 'orangeish', \"lab's\", 'inwas', 'polyestery', 'tinselly', 'really0', 'lslightly', 'theblack', 'benea', \"4'10\", 'tiiny', 'westher', 'knee0', 'flirtier', 'leggier', 'forwar', \"'short'\", 'lightwe', 'completly', \"nolan's\", 'antrhopologie', 'especailly', \"does't\", 'addit', 'picure', 'sooooooo', 'agustable', 'satin0like', 'retun', 'waify', 'colw', 'tummmy', 'anothe', 'stumpified', 'nevery', 'wrapover', 'rpetty', 'eprson', \"everyone's\", \"36dd's\", 'lb\\r', 'untextured', \"mean's\", 'reccomended', '38ish', 'shooties', \"'peach'\", 'oetite', 'creater', 'highe', 'deshn', \"hei's\", 'witho', \"they''d\", \"anthto's\", 'a34b', 'lenth', 'loosly', \"143lb's\", '108lbs', \"patrick's\", \"sparrow's\", \"'baggish'\", \"'summer'\", 'bandaid', 'cartionnier', \"5'0'\", '25petite', 'fadng', 'whelming', \"'delicateness'\", \"kimono's\", '36e', \"'cover\", \"up'\", 'comparat', 'uncomfotably', 'stitchin', 'halterneck', 'mayb', 'shlumpy', 'satisfi', 'anthto', 'jns', 'buttyondown', 'eucalan', 'twirly', 'saggier', 'anyday', \"'honey\", \"slip'\", \"90's\", 'hoepfulyl', 'orffice', 'sizingwise', '5lbs', 'fluffiness', '95lb', 'itnended', 'aame', 'apttern', 'minorly', 'unmodest', \"'supposed\", 'pashminas', 'accessorize\\r', 'clasic', 'looovvveee', 'transistional', \"jacket's\", 'comforable', 'morher', 'launderings', 'brainier', 'talls', \"i'\", 'hipbones', 'blousier', 'henely', 'janeausten', 'stright', \"din'dt\", 'wrikling', 'wwear', 'looooove', 'casualed', 'compfy', 'unflatering', \"'older'\", \"1''\", \"3''\", 'plasticy', \"haven'\", 'itll', \"picture's\", 'explosing', \"'larger'\", 'loosness', 'chubbiness', \"she'd\", 'small\\r', '28l', \"'hard'\", 'huuuuge', \"i'm\\r\", 'fit\\r', 'is\\r', \"brand's\", 'skosh', '134lb', 'pouching', 'waistless', 'person\\r', '122lb', 'peice', '115ish', 'sleeeves', 'definetly', \"didm't\", \"'70's\", 'different\\r', 'belted\\r', 'laceing', 'sparklecolor', 'flipflops', 'imwas', 'imput', 'forarms', 'feminie', 'foldover', \"la's\", '117bl', 'antheropologie', 'differen', 'ladyish', 'waitband', \"'different\", \"'puckered'\", 'pintucks', 'mishaped', 'scated', 'althleisure', 'syle', \"'floppy'\", 'beautifullly', 'detsils', 'recomnend', 'comfotably', 'breastline', 'sillouhette', 'lovethis', 'pacquerette', 'anwen', 'wayyyyy', 'hundo', \"sayin'\", 'camsiole', 'campole', 'neckli', 'toosh', '42dd', 'through\\r', 'princessy', 'complection', \"'boyfriend'\", 'stre', '36j', 'santuary', 'wrappi', 'thiner', 'cooold', 'loook', 'regularl', 'petittes', 'lol\\r', \"grandmother's\", 'nocal', \"shoulder'd\", '180lbs', 'airism', \"5'6'\", 'length\\r', 'overywhelming', \"product's\", 'sidezip', 'supercute', \"o'\", \"all'\", 'pilazzo', 'unshapely', \"combo's\", 'regardi', 'desideria', 'tops\\r', 'aleardy', \"6'3\", 'frumpiness', \"wheatley's\", '4petite', 'maternityish', 'cheapish', 'etiher', 'crumply', 'conside', \"'pink'\", 'swingyness', \"floreat's\", 'usuall', 'widelegs', 'lilka', 'shirty', 'shininess', 'quaiity', 'am\\r', 'were\\r', 'plasticky', 'lineba', \"'shell'\", 'exteemely', 'sinched', 'regualar', 'mentioend', \"maxi's\", 'unbuttons', \"girls'\", 'with\\r', 'stetchy', 'differemt', 'anafa', 'estatic', 'aaaahmazing', 'sohpisticated', '116bs', 'regulr', 'stretchs', 'humd', 'dissappointed', 'handwashable', '32e', 'apetite', 'poofier', \"'stressed'\", '5stars', 'unsnapped', 'mauv', 'eaisly', '40yo', 'surprisngly', 'tightish', 'shown\\r', 'store\\r', 'retailerday', 'not\\r', \"5'61\", 'contri', 'blaclk', 'dã©colletã©', \"'weather'\", \"sunday's\", 'littl', 'resewn', \"swimmer's\", 'redyed', 'shapelessness', '111lbs', \"lovin'\", 'lenght', 'shortwaisted', 'iwould', 'ehels', 'perhpas', 'frnt', 'amoret', 'sexyness', \"hyphen's\", \"person's\", 'recei', 'needlenose', 'comfie', 'goodhyouman', 'florascura', 'sassing', 'often\\r', 'compar', \"'cream'\", 'turend', 'thanskgiving', 'amaz', 'looooooove', 'colorblocked', 'veltevty', 'comfim', 'dissapointing', 'plackets', \"body's\", \"driver's\", 'outsi', 'snuggest', 'puffier', 'oprefer', 'aottern', 'coverd', 'colorblocking', 'itlooks', \"they'r\", 'amost', 'rediculous', 'f21', '36dddd', 'beautifu', '10lbs', 'godets', 'hastle', 'camisol', 'supersoft', 'unstitch', 'essentiel', 'floofs', 'clevage', \"'cos\", 'repeller', \"ladies'\", 'strops', 'allways', \"'faux\", \"cardi'\", 'slvs', \"'timeless'\", 'tangl', 'bottam', \"'great\", 'youthfull', 'fallish', 'material\\r', 'odrdered', 'swaeter', \"'sunless\", \"shift'\", \"lilke's\", 'tideline', 'perferred', \"father's\", \"voila'\", 'medlum', \"5'2'\", \"i'l\", 'mabli', 'huuuuggge', 'jaclket', 'aroun', 'definitly', 'sweatshirty', 'coplaints', 'nikrooz', 'dynam', 'returrn', 'acceptabl', 'armhoes', 'accesso', 'rusn', \"'help'\", '133lbs', 'pilly', 'shld', 'xsma', \"'nightgown'\", \"5''5\", \"9''\", 'mensware', 'lengh', 'kindof', 'michigans', 'lable', '5ft8inches', 'rackerback', 'gorgeus', 'cutwork', \"xl's\", \"'greener'\", 'contrastin', 'loosley', \"'fall'\", 'ingnore', 'ithis', '134lbs', 'starts\\r', 'givinng', \"dnd't\", 'opitome', 'referance', 'imhave', 'lululemons', '144lb', 'anth', 'weara', 'nred', 'compaint', 'ldecide', '11and', 'besutiful', 'ahtro', 'antropologie', \"'must\", \"have'\", 'armh', 'ã¼ber', 'bsck', 'riiiiiiiiiip', 'isalmsot', 'zipepr', 'vanit', 'kahki', \"tee's\", 'enoug', 'goldilicks', 'orderer', '140b', '154lbs', 'breasting', 'christmas1', 'runching', 'don\\r', 'up\\r', 'color\\r', 'fabric\\r', 'much\\r', \"'online\", \"exclusive'\", 'disap', 'undnerneath', 'lysee', 'everywhe', 'attentio', \"ddind't\", 'lcome', \"idea's\", 'meleri', 'waaaay', 'ldecided', 'seemd', 'detaisl', '116ibs', '2regular', \"don''t\", 'vribant', 'hesitent', \"25''\", 'pintuck', 'neckes', '36dds', 'fluevogs', 'srink', \"6'0\", 'glams', 'romier', 'sizze', 'chokey', \"xs's\", 'costumey', 'oversharing', '30gg', 'volumptuous', 'thinkness', 'oclor', 'colos', 'greal', 'pictur', 'cahnce', 'howeverm', 'sueded', \"pocket's\", 'lighweight', \"preggo's\", 'blousing', 'slinder', 'accomadate', \"'runs\", \"large'\", \"it'a\", 'becaus', 'unfrotuantely', 'ooopss', 'midrise', 'swlim', 'emobroidery', \"5'2'm\", 'xspwas', 'recievied', 'substan', \"7's\", \"that'll\", 'sheerish', 'otherwsie', 'mifnight', 'laways', 'coth', 'stonw', 'scrunchy', 'goood', 'latetly', 'purchasi', 'agai', 'boyshort', \"did't\", \"'stuck'\", 'pouffier', \"'90's\", 'dr4ess', '7months', 'preggars', 'turqoise', 'earrin', 'complected', \"wren't\", 'unproportioned', 'conditionied', 'strangly', \"summer's\", \"sewer's\", \"6's\", 'shoulder\\r', 'anrtho', 'flatting', 'wonderul', 'oredered', 'refgular', 'strectchy', 'stiched', 'adjsut', 'underbust', 'people\\r', 'then\\r', 'legs\\r', 'purc', 'tmie', 'isthe', 'lfit', 'lnever', 'athropologie', 'staticy', \"stone's\", 'bating', \"preschooler's\", \"ii'm\", 'review\\r', 'adoreable', 'ddd36', \"momma's\", \"don't'\", '134b', 'postur', 'from\\r', 'xxsmall', 'pictured\\r', 'down\\r', 'mislabel', \"t'shirt\", 'f\\r', 'recomend', 'monthe', 'yey', 'simpleness', 'birkinstocks', 'jodphurs', 'sz12', \"superman'd\", 'drearriest', '5ft3in', \"1970's\", \"antropologie's\", \"law's\", 'weddingrehearsal', 'drapy', 'dalls', 'prepregnancy', 'bedskirt', 'flecking', 'swim\\r', 'compareed', 'iand', 'gianormous', 'retailerplogie', 'bustiest', 'senitive', 'approprialty', 'musually', 'malfun', \"reese's\", \"69's\", \"'smoky'\", 'pilcr', 'flar', 'construc', \"god's\", 'middl', \"'gathered\", 'allllllmost', 'supersexy', 'has\\r', 'as\\r', 'eliding', \"'bubble\", \"butt'\", 'wiast', 'nuetral', \"5's\", \"5''6\", 'sofisticated', \"naomi's\", 'pouffy', \"cheerleader's\", 'beatifully', \"'flair'\", 'lke', 'rainproof', \"dog's\", 'reweave', 'sleveless', 'garmet', '128b', \"it's'\", '125ibs', 'stets', 'gourgeous', 'inwonderland', 'anyou', 'theighs', 'horizont', 'packable', 'cycl', 'uniquenesses', 'thighed', 'goldish', 'finially', \"5'130lbs\", 'reache', \"back's\", 'retur', 'henleys', 'hoiday', 'plesantly', 'taffita', 'asummig', 'ocassionally', 'substancial', 'tirst', \"mightn't\", 'southwesternish', \"'red\", \"orange'\", \"'drape'\", 'strappiness', \"doesn'\", 'afterwork', 'llonger', \"29's\", \"sui's\", '3rds', 'eptites', 'msut', 'wrng', 'tucke', 'odering', 'cinderalla', \"'chunky'\", \"'softens'\", \"'more'\", \"'closet\", \"sitter'\", 'textiled', 'szie', 'looke', 'aweful', 'ahge', 'palelike', 'asflattering', 'loooove', 'everyth', \"jacket'ish\", 'anyt', \"'pull\", 'impecable', 'couldve', \"'ivory'\", 'nirsing', 'produ', 'suppre', 'uppe', 'raunching', 'firned', 'impresssionistic', \"'5\", 'aplique', 'mamaw', \"0's\", 'relazation', 'size\\r', 'biggy', 'elasticised', 'bulkly', 'sandscape', 'availalbe', 'lwait', \"husband''s\", 'navy\\r', 'perfectly\\r', 'reveive', 'crwal', 'awkwards', 'comfrtable', '125b', 'sinches', \"'ride'\", 'lokka', '190lbs', 'materical', 'problemo', \"stylist's\", 'colsely', 'mentione', 'boxines', 'sihrt', 'sexified', 'ecause', 'tbu', 'snugged', 'elastaine', 'definitel', 'pratically', \"'moss'\", \"artist's\", '220lbs', 'unike', 'slinkiness', 'overstitching', 'ribbbed', 'xxxxxs', '3xxxl', 'dl1961s', 'athro', \"'railroad\", \"tracks'\", 'ruffl', 'my3', \"30''\", \"31''\", '5ft7', \"barbie's\", \"1950's\", 'crinolined', \"sa's\", 'pirces', 'nexl', 'pcture', 'teeshirt', 'wrinkel', 'butit', \"etro's\", '30lbs', '137lbs', 'thrille', 'wideness', 'dã©colletage', 'bellowy', 'peittes', 'ridic', 'entirel']\n"
     ]
    }
   ],
   "source": [
    "print(review_word_not_in_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1943\n"
     ]
    }
   ],
   "source": [
    "print(review_word_not_in_glove_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similar text preprocessing for Title below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the lines having unique length size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_elements, counts_elements = np.unique(data_string_train['Title'].apply(len),return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9,  36, 170, 172, 163, 301, 518, 500, 602, 586, 582, 619, 656,\n",
       "       719, 663, 524, 565, 518, 547, 432, 370, 355, 353, 310, 322, 232,\n",
       "       228, 216, 186, 205, 155, 151, 136, 115, 109, 102, 116,  75,  79,\n",
       "        63,  54,  59,  46,  41,  47,  30,  38,  42,  54,   2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the Max Sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_text_count_length = list(counts_elements).index(max(counts_elements))\n",
    "TITLE_MAX_SEQUENCE_LENGTH = unique_elements[max_text_count_length]\n",
    "TITLE_MAX_SEQUENCE_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize the Title text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3117 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(oov_token='None')\n",
    "tokenizer.fit_on_texts(data_string_train['Title'])\n",
    "title_train = tokenizer.texts_to_sequences(data_string_train['Title'])\n",
    "title_test = tokenizer.texts_to_sequences(data_string_test['Title'])\n",
    "\n",
    "word_index_title = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index_title))\n",
    "NUM_WORDS_TITLE = len(word_index_title)+1\n",
    "\n",
    "title_text_seq_train = pad_sequences(title_train, maxlen=TITLE_MAX_SEQUENCE_LENGTH)\n",
    "title_text_seq_test = pad_sequences(title_test, maxlen=TITLE_MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also count the number of words not present in the glove to decide whether we need to train or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "title_embedding_matrix = np.zeros((NUM_WORDS_TITLE,50))\n",
    "title_word_not_in_glove_count = 0\n",
    "title_word_not_in_glove =[]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        title_embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        title_word_not_in_glove.append(word)\n",
    "        title_word_not_in_glove_count = title_word_not_in_glove_count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286\n"
     ]
    }
   ],
   "source": [
    "print(title_word_not_in_glove_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Clothing ID is not treated as a continuous variable since the values are repeating\n",
    "Since there are 1172 different values in 'Clothing ID' dummyfying it will cause sparser matrix (having many 0's)\n",
    "\n",
    "Therefore we are choosing to use categorical embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_id_levels_encoded=LabelEncoder().fit(data['Clothing ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_id_levels_encoded_train=clothing_id_levels_encoded.transform(data_clothingID_train)\n",
    "clothing_id_levels_encoded_test=clothing_id_levels_encoded.transform(data_clothingID_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model using functional api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical embedding of Clothing ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_id_input = Input(shape=(1, ), name=\"Clothing_ID\")\n",
    "clothing_id_embed = Embedding(input_dim=clothing_ID_levels, output_dim=50)(clothing_id_input)\n",
    "clothing_id_embed_flat = Flatten()(clothing_id_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense layer for numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.hstack((scaled_attr_test, OneHotEncoder_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cat_inputs = Input(shape=(X_train.shape[1],),name='num_cat_inputs')\n",
    "out_num_cat = Dense(64, activation='relu')(num_cat_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding layer for Review Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If there are more than one word in the training data which are not present in Glove then train the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text_input= Input(shape=(REVIEW_TEXT_MAX_SEQUENCE_LENGTH,),name='review_text_input')\n",
    "if (review_word_not_in_glove_count<=1):\n",
    "    text_embed = Embedding(input_dim=NUM_WORDS_REVIEW_TEXT,output_dim=50,weights=[review_embedding_matrix],trainable=False)(review_text_input)\n",
    "else:\n",
    "    text_embed = Embedding(input_dim=NUM_WORDS_REVIEW_TEXT,output_dim=50,weights=[review_embedding_matrix],trainable=True)(review_text_input)\n",
    "review_out_text = Flatten()(text_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding layer for Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_text_input= Input(shape=(TITLE_MAX_SEQUENCE_LENGTH,),name='title_text_input')\n",
    "if (title_word_not_in_glove_count<=1):\n",
    "    text_embed = Embedding(input_dim=NUM_WORDS_TITLE,output_dim=50,weights=[title_embedding_matrix],trainable=False)(title_text_input)\n",
    "else:\n",
    "    text_embed = Embedding(input_dim=NUM_WORDS_TITLE,output_dim=50,weights=[title_embedding_matrix],trainable=True)(title_text_input)\n",
    "title_out_text = Flatten()(text_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate the output of above layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated = concatenate([clothing_id_embed_flat,out_num_cat,review_out_text,title_out_text],axis=-1)\n",
    "X = Dense(8, activation='relu')(concatenated)\n",
    "final_out = Dense(no_of_levels, activation='softmax')(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[clothing_id_input,num_cat_inputs,review_text_input,title_text_input], outputs=final_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Clothing_ID (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "review_text_input (InputLayer)  (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_text_input (InputLayer)   (None, 15)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 50)        54750       Clothing_ID[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "num_cat_inputs (InputLayer)     (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 500, 50)      599350      review_text_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 15, 50)       155900      title_text_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 50)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           2112        num_cat_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 25000)        0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 750)          0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 25864)        0           flatten_1[0][0]                  \n",
      "                                                                 dense_1[0][0]                    \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            206920      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5)            45          dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,019,077\n",
      "Trainable params: 1,019,077\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10538 samples, validate on 2635 samples\n",
      "Epoch 1/10\n",
      "10538/10538 [==============================] - 6s 613us/step - loss: 1.0095 - acc: 0.5925 - val_loss: 0.9247 - val_acc: 0.6011\n",
      "Epoch 2/10\n",
      "10538/10538 [==============================] - 6s 571us/step - loss: 0.8288 - acc: 0.6289 - val_loss: 0.8920 - val_acc: 0.6091\n",
      "Epoch 3/10\n",
      "10538/10538 [==============================] - 6s 570us/step - loss: 0.7662 - acc: 0.6461 - val_loss: 0.8798 - val_acc: 0.6137\n",
      "Epoch 4/10\n",
      "10538/10538 [==============================] - 6s 568us/step - loss: 0.7131 - acc: 0.6831 - val_loss: 0.8746 - val_acc: 0.6296\n",
      "Epoch 5/10\n",
      "10538/10538 [==============================] - 6s 535us/step - loss: 0.6652 - acc: 0.7247 - val_loss: 0.8730 - val_acc: 0.6304\n",
      "Epoch 6/10\n",
      "10538/10538 [==============================] - 6s 532us/step - loss: 0.6162 - acc: 0.7556 - val_loss: 0.8865 - val_acc: 0.6307\n",
      "Epoch 7/10\n",
      "10538/10538 [==============================] - 6s 565us/step - loss: 0.5613 - acc: 0.7843 - val_loss: 0.8708 - val_acc: 0.6368\n",
      "Epoch 8/10\n",
      "10538/10538 [==============================] - 6s 562us/step - loss: 0.4982 - acc: 0.8164 - val_loss: 0.8853 - val_acc: 0.6414\n",
      "Epoch 9/10\n",
      "10538/10538 [==============================] - 6s 568us/step - loss: 0.4449 - acc: 0.8341 - val_loss: 0.9126 - val_acc: 0.6247\n",
      "Epoch 10/10\n",
      "10538/10538 [==============================] - 6s 572us/step - loss: 0.3996 - acc: 0.8565 - val_loss: 0.9323 - val_acc: 0.6345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x136d3e828>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([clothing_id_levels_encoded_train,X_train,\n",
    "           review_text_seq_train,title_text_seq_train], \n",
    "          y=OneHotEncoder_target_train, \n",
    "          epochs=10,validation_split=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13173/13173 [==============================] - 1s 103us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47434727256303316, 0.8296515600453076]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([clothing_id_levels_encoded_train,X_train,review_text_seq_train,title_text_seq_train], \n",
    "               y=OneHotEncoder_target_train, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6489/6489 [==============================] - 1s 128us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9200684088351896, 0.6437047311109283]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([clothing_id_levels_encoded_test,X_test,review_text_seq_test,title_text_seq_test], \n",
    "               y=OneHotEncoder_target_test, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.22871893e-11, 5.96595706e-09, 2.86042516e-04, 5.86297363e-03,\n",
       "        9.93850946e-01],\n",
       "       [3.20166582e-03, 5.61929606e-02, 6.42572790e-02, 6.69453621e-01,\n",
       "        2.06894472e-01],\n",
       "       [2.46309161e-01, 3.54032487e-01, 3.51960301e-01, 1.21067669e-02,\n",
       "        3.55912820e-02],\n",
       "       ...,\n",
       "       [2.33408791e-05, 9.01696563e-04, 1.01095371e-01, 5.98917484e-01,\n",
       "        2.99062163e-01],\n",
       "       [1.40292281e-02, 8.35757732e-01, 6.50851149e-03, 1.30809769e-01,\n",
       "        1.28948325e-02],\n",
       "       [2.00589781e-10, 8.42359640e-08, 1.12169808e-04, 9.48648620e-03,\n",
       "        9.90401328e-01]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([clothing_id_levels_encoded_test,X_test,review_text_seq_test,title_text_seq_test])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
